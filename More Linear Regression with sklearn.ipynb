{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "For each of the Theta vectors below, find the decision boundary, and give an example of a point that would get classified as Class 0 and a point that would get classified as Class 1. (There isn't really any Python coding to do here, so you can just type your answers below.)\n",
    "<ol>\n",
    "    <li> $\\theta =[5,-2]$ </li> \n",
    "     <li> $\\theta =[5,-2,3]$ </li> \n",
    "     <li> $\\theta =[5,-2,3,-4]$ </li> \n",
    "     <li> $\\theta =[5,-2,3,-4,1]$ </li> \n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $-5 + 2x_1 = 0$, therefore $x_1 = \\frac{5}{2}$ \\\n",
    "class0 = 1, class1 = 4 \n",
    "2. $-5 + 2x_1 - 3x_2 = 0$, therefore $x_2 = \\frac{5}{3} - \\frac{2}{3}x_1$ \\\n",
    "class0 = (-1,1), class1 = (-3,3)\n",
    "3. $-5 + 2x_1 - 3x_2 + 4x_3 = 0$, therefore $x_3 = \\frac{5}{4} - \\frac{2}{4}x_1 + \\frac{3}{4}x_2$ \\\n",
    "class0 = (0,0,0), class1 = (-3,2,5)\n",
    "4. $-5 + 2x_1 - 3x_2 + 4x_3 - 1x_4 = 0$, therefore $x_4 = -5+2x_1 - 3x_2 + 4x_3$ \\\n",
    "class0 = (1,0,0,-1), class1 = (1,0,0,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Compare the three different methods of Scaling/Normalizing data from sklearn on the given $X$ vector. Explain what each technique is doing to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell is just set up.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X=np.array([1.0,5,-2,4,-6,7,2,-8,9,0])\n",
    "X=X.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03880753],\n",
       "       [ 0.737343  ],\n",
       "       [-0.62092042],\n",
       "       [ 0.54330537],\n",
       "       [-1.39707095],\n",
       "       [ 1.12541826],\n",
       "       [ 0.15523011],\n",
       "       [-1.78514621],\n",
       "       [ 1.51349353],\n",
       "       [-0.23284516]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Example for first method = StandardScaler\n",
    "scaler1=StandardScaler()\n",
    "Xss=scaler1.fit(X)\n",
    "scaler1.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A) What does StandardScaler do? \\\n",
    "    `StandardScalar` essentialy standardizes the data using the mean sample difference divided by the stadard deviation.  By checking `StandardScalar?`, it states the function will remove the mean and scales the data to the unit variance. \\\n",
    "Source \"scikit-learn 0.22.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) Explain what the following code is doing and why it is important. \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2]\n",
      "[5.15363949]\n"
     ]
    }
   ],
   "source": [
    "print(scaler1.mean_)\n",
    "print(scaler1.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scaler1.mean_` is printing the mean of the standardized values which are the same as the mean of the original array X.  `scaler1.scale_` is printing the standard deviation of the scales which is the same as the standard deviation of X.  The code is important because it allows one to access the scales and to see that the scaling is working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C)  Repeat (A) and (B) as above for MinMaxScaler in place of StandardScaler and explain what that method is doing. You'll need to think about what the appropriate parameters are for MinMaxScaler for (B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52941176],\n",
       "       [0.76470588],\n",
       "       [0.35294118],\n",
       "       [0.70588235],\n",
       "       [0.11764706],\n",
       "       [0.88235294],\n",
       "       [0.58823529],\n",
       "       [0.        ],\n",
       "       [1.        ],\n",
       "       [0.47058824]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Example for second method: MinMaxScaler\n",
    "scaler2=MinMaxScaler()\n",
    "Xmms=scaler2.fit(X)\n",
    "scaler2.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A) What does MinMaxSacler() do? \\\n",
    "This is another normalizing technique that uses the min and max (a range) to scale the data. Based on `MinMaxScaler?` it states that the function will transform features by scaling each feature to a given range.\n",
    "\"This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one.\" \\\n",
    "source: scikit-learn 0.22.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) Explain what the following code is doing and why it's important \\\n",
    "The following code outputs the raw data's min and max while showing the scale when normalizing the data.  This is useful because we can see if the scaling works and well as it gives us the possibility to save the scaling factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.]\n",
      "[9.]\n",
      "[0.05882353]\n"
     ]
    }
   ],
   "source": [
    "print(scaler2.data_min_)\n",
    "print(scaler2.data_max_)\n",
    "print(scaler2.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11111111],\n",
       "       [ 0.55555556],\n",
       "       [-0.22222222],\n",
       "       [ 0.44444444],\n",
       "       [-0.66666667],\n",
       "       [ 0.77777778],\n",
       "       [ 0.22222222],\n",
       "       [-0.88888889],\n",
       "       [ 1.        ],\n",
       "       [ 0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Example for third method: MaxAbsScaler\n",
    "scaler3=MaxAbsScaler()\n",
    "Xmas=scaler3.fit(X)\n",
    "scaler3.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A) What does MaxAbsScaler do? \\\n",
    "A scaling technique which will scale each feature by its absolute maximum value.  By doing `MaxAbsScaler?` we see that the estimator scales and translates each feature individually \"such that the maximal absolute value of each feature in the training set will be 1.0. It does not shift/center the data, and thus does not destroy any sparsity\" \\\n",
    "source: scikit-learn 0.22.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) Explain what the following code is doing and why it's important \\\n",
    "The paramters include the max absolute values from ther raw data as well as the scale factor.  It is worth while to save the scaling incase one needs to rescale later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.]\n",
      "[9.]\n"
     ]
    }
   ],
   "source": [
    "print(scaler3.max_abs_)\n",
    "print(scaler3.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Use sklearn to redo your linear regression from HW due Jan 27, Question 3. That is:\n",
    "<br>\n",
    "(A) Create an X which contains only the features you used before.\n",
    "<br>\n",
    "(B) Drop NaNs and Normalize the data. (Use one of the sklearn functions to do the Normalization now.)\n",
    "<br>\n",
    "(C) Perform the Linear Regression using sklearn commands and output your $\\theta$ vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Life expectancy</th>\n",
       "      <th>Adult Mortality</th>\n",
       "      <th>Infant deaths</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>percentage expenditure</th>\n",
       "      <th>Hepatitis B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>BMI</th>\n",
       "      <th>under-five deaths</th>\n",
       "      <th>Polio</th>\n",
       "      <th>Total expenditure</th>\n",
       "      <th>Diphtheria</th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Population</th>\n",
       "      <th>thinness  1-19 years</th>\n",
       "      <th>thinness 5-9 years</th>\n",
       "      <th>Income composition of resources</th>\n",
       "      <th>Schooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>2928.000000</td>\n",
       "      <td>2928.000000</td>\n",
       "      <td>2938.000000</td>\n",
       "      <td>2744.000000</td>\n",
       "      <td>2938.000000</td>\n",
       "      <td>2385.000000</td>\n",
       "      <td>2938.000000</td>\n",
       "      <td>2904.000000</td>\n",
       "      <td>2938.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2712.00000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2938.000000</td>\n",
       "      <td>2490.000000</td>\n",
       "      <td>2.286000e+03</td>\n",
       "      <td>2904.000000</td>\n",
       "      <td>2904.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2775.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>69.224932</td>\n",
       "      <td>164.796448</td>\n",
       "      <td>30.303948</td>\n",
       "      <td>4.602861</td>\n",
       "      <td>738.251295</td>\n",
       "      <td>80.940461</td>\n",
       "      <td>2419.592240</td>\n",
       "      <td>38.321247</td>\n",
       "      <td>42.035739</td>\n",
       "      <td>82.550188</td>\n",
       "      <td>5.93819</td>\n",
       "      <td>82.324084</td>\n",
       "      <td>1.742103</td>\n",
       "      <td>7483.158469</td>\n",
       "      <td>1.275338e+07</td>\n",
       "      <td>4.839704</td>\n",
       "      <td>4.870317</td>\n",
       "      <td>0.627551</td>\n",
       "      <td>11.992793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>9.523867</td>\n",
       "      <td>124.292079</td>\n",
       "      <td>117.926501</td>\n",
       "      <td>4.052413</td>\n",
       "      <td>1987.914858</td>\n",
       "      <td>25.070016</td>\n",
       "      <td>11467.272489</td>\n",
       "      <td>20.044034</td>\n",
       "      <td>160.445548</td>\n",
       "      <td>23.428046</td>\n",
       "      <td>2.49832</td>\n",
       "      <td>23.716912</td>\n",
       "      <td>5.077785</td>\n",
       "      <td>14270.169342</td>\n",
       "      <td>6.101210e+07</td>\n",
       "      <td>4.420195</td>\n",
       "      <td>4.508882</td>\n",
       "      <td>0.210904</td>\n",
       "      <td>3.358920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>36.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.37000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.681350</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>63.100000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>4.685343</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>4.26000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>463.935626</td>\n",
       "      <td>1.957932e+05</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.493000</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>72.100000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.755000</td>\n",
       "      <td>64.912906</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>5.75500</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1766.947595</td>\n",
       "      <td>1.386542e+06</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>12.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>75.700000</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>7.702500</td>\n",
       "      <td>441.534144</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>360.250000</td>\n",
       "      <td>56.200000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>7.49250</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>5910.806335</td>\n",
       "      <td>7.420359e+06</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.779000</td>\n",
       "      <td>14.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>723.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>17.870000</td>\n",
       "      <td>19479.911610</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>212183.000000</td>\n",
       "      <td>87.300000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>17.60000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>50.600000</td>\n",
       "      <td>119172.741800</td>\n",
       "      <td>1.293859e+09</td>\n",
       "      <td>27.700000</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>20.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Life expectancy   Adult Mortality  Infant deaths      Alcohol  \\\n",
       "count       2928.000000      2928.000000    2938.000000  2744.000000   \n",
       "mean          69.224932       164.796448      30.303948     4.602861   \n",
       "std            9.523867       124.292079     117.926501     4.052413   \n",
       "min           36.300000         1.000000       0.000000     0.010000   \n",
       "25%           63.100000        74.000000       0.000000     0.877500   \n",
       "50%           72.100000       144.000000       3.000000     3.755000   \n",
       "75%           75.700000       228.000000      22.000000     7.702500   \n",
       "max           89.000000       723.000000    1800.000000    17.870000   \n",
       "\n",
       "       percentage expenditure  Hepatitis B       Measles           BMI  \\\n",
       "count             2938.000000  2385.000000    2938.000000  2904.000000   \n",
       "mean               738.251295    80.940461    2419.592240    38.321247   \n",
       "std               1987.914858    25.070016   11467.272489    20.044034   \n",
       "min                  0.000000     1.000000       0.000000     1.000000   \n",
       "25%                  4.685343    77.000000       0.000000    19.300000   \n",
       "50%                 64.912906    92.000000      17.000000    43.500000   \n",
       "75%                441.534144    97.000000     360.250000    56.200000   \n",
       "max              19479.911610    99.000000  212183.000000    87.300000   \n",
       "\n",
       "       under-five deaths         Polio  Total expenditure  Diphtheria   \\\n",
       "count         2938.000000  2919.000000         2712.00000  2919.000000   \n",
       "mean            42.035739    82.550188            5.93819    82.324084   \n",
       "std            160.445548    23.428046            2.49832    23.716912   \n",
       "min              0.000000     3.000000            0.37000     2.000000   \n",
       "25%              0.000000    78.000000            4.26000    78.000000   \n",
       "50%              4.000000    93.000000            5.75500    93.000000   \n",
       "75%             28.000000    97.000000            7.49250    97.000000   \n",
       "max           2500.000000    99.000000           17.60000    99.000000   \n",
       "\n",
       "          HIV/AIDS            GDP    Population  thinness  1-19 years  \\\n",
       "count  2938.000000    2490.000000  2.286000e+03           2904.000000   \n",
       "mean      1.742103    7483.158469  1.275338e+07              4.839704   \n",
       "std       5.077785   14270.169342  6.101210e+07              4.420195   \n",
       "min       0.100000       1.681350  3.400000e+01              0.100000   \n",
       "25%       0.100000     463.935626  1.957932e+05              1.600000   \n",
       "50%       0.100000    1766.947595  1.386542e+06              3.300000   \n",
       "75%       0.800000    5910.806335  7.420359e+06              7.200000   \n",
       "max      50.600000  119172.741800  1.293859e+09             27.700000   \n",
       "\n",
       "       thinness 5-9 years  Income composition of resources    Schooling  \n",
       "count         2904.000000                      2771.000000  2775.000000  \n",
       "mean             4.870317                         0.627551    11.992793  \n",
       "std              4.508882                         0.210904     3.358920  \n",
       "min              0.100000                         0.000000     0.000000  \n",
       "25%              1.500000                         0.493000    10.100000  \n",
       "50%              3.300000                         0.677000    12.300000  \n",
       "75%              7.200000                         0.779000    14.300000  \n",
       "max             28.600000                         0.948000    20.700000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's data that you used before.\n",
    "import pandas as pd\n",
    "URL = 'http://facweb1.redlands.edu/fac/joanna_bieri/machinelearning/LifeExpectancyData.csv'\n",
    "df = pd.read_csv(URL)\n",
    "df.drop('Country', axis=1, inplace=True)\n",
    "df.drop('Year', axis=1, inplace=True)\n",
    "df.drop('Status', axis=1, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of df_new is: \n",
      " (2938, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Schooling</th>\n",
       "      <th>Income composition of resources</th>\n",
       "      <th>Life expectancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.479</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.476</td>\n",
       "      <td>59.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.470</td>\n",
       "      <td>59.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.463</td>\n",
       "      <td>59.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.454</td>\n",
       "      <td>59.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Schooling  Income composition of resources  Life expectancy \n",
       "0     0.01       10.1                            0.479              65.0\n",
       "1     0.01       10.0                            0.476              59.9\n",
       "2     0.01        9.9                            0.470              59.9\n",
       "3     0.01        9.8                            0.463              59.5\n",
       "4     0.01        9.5                            0.454              59.2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an X which contains only the features you used before. \n",
    "\n",
    "df_X = df[['Alcohol', 'Schooling', 'Income composition of resources', 'Life expectancy ']].copy()\n",
    "print(\"the shape of df_new is: \\n\", df_X.shape)\n",
    "df_X.dropna(inplace=True)\n",
    "df_X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I dont want to normalize my y so I broke it up after removing NA's \n",
    "\n",
    "df_data = df_X[['Alcohol', 'Schooling', 'Income composition of resources']].copy()\n",
    "df_target = df_X[['Life expectancy ']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.12570563 -0.58208997 -0.70116261]\n",
      " [-1.12570563 -0.6126342  -0.71543321]\n",
      " [-1.12570563 -0.64317844 -0.7439744 ]\n",
      " ...\n",
      " [-0.02255412 -0.6126342  -0.94851959]\n",
      " [-0.69892077 -0.67372268 -0.94851959]\n",
      " [-0.70890404 -0.67372268 -0.91522153]]\n"
     ]
    }
   ],
   "source": [
    "# normalize data using StandardScalar\n",
    "\n",
    "scaler_a = StandardScaler()\n",
    "Xsc = scaler_a.fit(df_data)\n",
    "X_norm = scaler_a.transform(df_data)\n",
    "print(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2584, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "(2584, 1)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use sklearn package to do Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()  ## just a shortcut to type less\n",
    "X=X_norm  ##Note the double brackets [[]] makes X a DataFrame \n",
    "print(X_norm.shape)\n",
    "print(type(X_norm))\n",
    "Y=df_target  ## Y is a df\n",
    "print(Y.shape)\n",
    "print(type(Y))\n",
    "lm.fit(X,Y)  ## The .fit command performs the linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69.29732972]\n",
      "<class 'numpy.ndarray'>\n",
      "[[-0.45263069  4.79482673  3.11787864]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([69.29732972, -0.45263069,  4.79482673,  3.11787864])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0 = lm.intercept_ # theta0 is the intercept \n",
    "print(theta0)\n",
    "thetas = lm.coef_\n",
    "print(type(thetas))\n",
    "print(thetas)\n",
    "params = np.hstack((theta0[0], thetas[0,:])) # stack all thetas into one array\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 \n",
    "Repeat the above but use the other normalization technique from above. How did the theta parameters change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0005596  0.48792271 0.50527426]\n",
      " [0.0005596  0.48309179 0.5021097 ]\n",
      " [0.0005596  0.47826087 0.49578059]\n",
      " ...\n",
      " [0.24790151 0.48309179 0.45042194]\n",
      " [0.0962507  0.47342995 0.45042194]\n",
      " [0.09401231 0.47342995 0.45780591]]\n",
      "(2584, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "(2584, 1)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[42.93473474]\n",
      "[[-2.01874491 30.31604634 14.06009828]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([42.93473474, -2.01874491, 30.31604634, 14.06009828])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using MaxAbsScaler to normalize\n",
    "scaler_b = MaxAbsScaler()\n",
    "X = scaler_b.fit(df_data)\n",
    "X_norm = scaler_b.transform(df_data)\n",
    "print(X_norm)\n",
    "\n",
    "# linear regression from SkiLearn\n",
    "lm = LinearRegression()  ## just a shortcut to type less\n",
    "X=X_norm  ##Note the double brackets [[]] makes X a DataFrame \n",
    "print(X_norm.shape)\n",
    "print(type(X_norm))\n",
    "Y=df_target \n",
    "print(Y.shape)\n",
    "print(type(Y))\n",
    "lm.fit(X,Y)  ## The .fit command performs the linear regression \n",
    "\n",
    "# find thetas\n",
    "theta0 = lm.intercept_\n",
    "print(theta0)\n",
    "thetas = lm.coef_\n",
    "print(thetas)\n",
    "params=np.hstack((theta0, thetas[0]))\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My $\\theta$ changed quite a bit from the $\\theta$s I recieved from the StandardScaler. They went from: \\\n",
    "array([69.29732972, -0.45263069,  4.79482673,  3.11787864]) to \\\n",
    "array([42.93473474, -2.01874491, 30.31604634, 14.06009828]). \\\n",
    "The $\\theta$s remained in the same \"order\", where $\\theta_0$ was the biggest and $\\theta_1$ was the smallest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Repeat the above but do not normalize the data before calling the LinearRegression() function. Instead call the LinearRegression() function with \n",
    "lm = LinearRegression(normalize=True). How did the theta parameters change? What is this doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2584, 1)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[42.93473474]\n",
      "[[-0.11296838  1.4645433  14.8313273 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([42.93473474, -0.11296838,  1.4645433 , 14.8313273 ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_data\n",
    "\n",
    "lm = LinearRegression(normalize = True)  ## just a shortcut to type less\n",
    "Y = df_target  ## Y is still a Series, note shape.\n",
    "print(Y.shape)\n",
    "print(type(Y))\n",
    "lm.fit(X,Y)  ## The .fit command performs the linear regression \n",
    "\n",
    "# find thetas\n",
    "theta0 = lm.intercept_\n",
    "print(theta0)\n",
    "thetas = lm.coef_\n",
    "print(thetas)\n",
    "params=np.hstack((theta0, thetas[0]))\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\theta$s followed the same pattern where $\\theta_0$ is the largest and $\\theta_1$ is the smallest.  However, the actual values seem to be a compromise between the AbsMx method and the StandardScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "For your favorite normalization technique, pick a different set of 3-5 features and see how the theta parameters change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of df_new is: \n",
      " (2938, 5)\n",
      "(2574, 1)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[43.97512022]\n",
      "[[-3.66440079e-03  1.97591441e-01  2.81245167e+01  7.99047782e-02]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 4.39751202e+01, -3.66440079e-03,  1.97591441e-01,  2.81245167e+01,\n",
       "        7.99047782e-02])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X = df[['Infant deaths', 'Total expenditure', 'Income composition of resources', 'Diphtheria ', 'Life expectancy ']].copy()\n",
    "print(\"the shape of df_new is: \\n\", df_X.shape)\n",
    "df_X.dropna(inplace=True)\n",
    "df_X.head()\n",
    "\n",
    "df_data = df_X[['Infant deaths', 'Total expenditure', 'Income composition of resources', 'Diphtheria ']].copy()\n",
    "df_target = df_X[['Life expectancy ']].copy()\n",
    "\n",
    "X = df_data\n",
    "\n",
    "lm = LinearRegression(normalize = True)  ## just a shortcut to type less\n",
    "Y=df_target  ## Y is still a Series, note shape.\n",
    "print(Y.shape)\n",
    "print(type(Y))\n",
    "lm.fit(X,Y)  ## The .fit command performs the linear regression \n",
    "\n",
    "# find thetas\n",
    "theta0 = lm.intercept_\n",
    "print(theta0)\n",
    "thetas = lm.coef_\n",
    "print(thetas)\n",
    "params=np.hstack((theta0[0], thetas[0]))\n",
    "params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\theta$ values seem pretty similar despite it being output in scienfitific notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
